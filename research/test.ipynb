{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.54099\ttest-logloss:0.54412\n",
      "[1]\ttrain-logloss:0.46285\ttest-logloss:0.47311\n",
      "[2]\ttrain-logloss:0.41259\ttest-logloss:0.42798\n",
      "[3]\ttrain-logloss:0.37720\ttest-logloss:0.39660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\ttrain-logloss:0.34389\ttest-logloss:0.36607\n",
      "[5]\ttrain-logloss:0.32561\ttest-logloss:0.35102\n",
      "[6]\ttrain-logloss:0.30934\ttest-logloss:0.33700\n",
      "[7]\ttrain-logloss:0.28943\ttest-logloss:0.31933\n",
      "[8]\ttrain-logloss:0.27624\ttest-logloss:0.30951\n",
      "[9]\ttrain-logloss:0.26393\ttest-logloss:0.29986\n",
      "[10]\ttrain-logloss:0.25644\ttest-logloss:0.29326\n",
      "[11]\ttrain-logloss:0.24978\ttest-logloss:0.28816\n",
      "[12]\ttrain-logloss:0.23825\ttest-logloss:0.27908\n",
      "[13]\ttrain-logloss:0.23055\ttest-logloss:0.27346\n",
      "[14]\ttrain-logloss:0.22561\ttest-logloss:0.26950\n",
      "[15]\ttrain-logloss:0.22239\ttest-logloss:0.26682\n",
      "[16]\ttrain-logloss:0.21887\ttest-logloss:0.26466\n",
      "[17]\ttrain-logloss:0.21195\ttest-logloss:0.25931\n",
      "[18]\ttrain-logloss:0.20730\ttest-logloss:0.25488\n",
      "[19]\ttrain-logloss:0.20405\ttest-logloss:0.25261\n",
      "[20]\ttrain-logloss:0.20205\ttest-logloss:0.25186\n",
      "Accuracy: 0.8921996124031008\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target\n",
    "\n",
    "# Binarize the target variable for a classification task\n",
    "y_binary = (y > y.mean()).astype(int)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the dataset into DMatrix format, which is required by XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Define custom evaluation metric function\n",
    "def custom_accuracy(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds_binary = (preds > 0.5).astype(int)\n",
    "    accuracy = accuracy_score(labels, preds_binary)\n",
    "    return 'accuracy', accuracy\n",
    "\n",
    "# Define hyperparameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # Use binary logistic regression for binary classification\n",
    "    \"eval_metric\": \"logloss\"\n",
    "}\n",
    "\n",
    "# Training the model with early stopping and custom evaluation metric\n",
    "num_rounds = 1000  # Increase the number of rounds to allow for early stopping\n",
    "early_stopping_rounds = 20  # Number of rounds to wait for early stopping\n",
    "evals_result = {}  # Dictionary to store evaluation results\n",
    "model = xgb.train(params, dtrain, num_rounds, evals=[(dtrain, 'train'), (dtest, 'test')],\n",
    "                  evals_result=evals_result, verbose_eval=True, maximize=True,\n",
    "                #   custom_metric=custom_accuracy, \n",
    "                  early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "# Predictions\n",
    "y_pred_prob = model.predict(dtest)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)  # Binarize predictions using a threshold of 0.5\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Plotting the training and evaluation metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# train_metric = evals_result['train']['accuracy']\n",
    "# test_metric = evals_result['test']['accuracy']\n",
    "\n",
    "# plt.plot(train_metric, label='Train Accuracy')\n",
    "# plt.plot(test_metric, label='Test Accuracy')\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Training and Evaluation Metrics')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the maximum value: 4\n"
     ]
    }
   ],
   "source": [
    "my_list = [10, 30, 20, 20, 50, 50, 40]\n",
    "\n",
    "# Find the index of the maximum value\n",
    "max_index = my_list.index(max(my_list))\n",
    "\n",
    "print(\"Index of the maximum value:\", max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
